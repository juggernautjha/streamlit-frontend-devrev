{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llm': {'gpt-3.5-turbo': 'openAI', 'llama2': 'ollama'}, 'embedding': {'text-embedding-ada-002': 'openAI', 'llama2': 'ollama', 'all-MiniLM-L6-v2': 'sent'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.llms.ollama import Ollama\n",
    "import json\n",
    "import langchain\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings, OllamaEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import aux\n",
    "import yaml\n",
    "import typing\n",
    "\n",
    "model_map = yaml.load(open('model_map.yaml'), Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "print(model_map)\n",
    "\n",
    "#Util function\n",
    "def get_embedding_model(modelname : str, model_map : typing.Dict = model_map):\n",
    "    model_type = model_map[modelname].lower()\n",
    "    print(model_type)\n",
    "    try:\n",
    "        \n",
    "        if model_type == 'openai':\n",
    "            if not st.session_state['api_key'].startswith('sk-'):\n",
    "                    st.warning(st.session_state['api_key'])\n",
    "                    st.warning('Please enter your OpenAI API key!', icon='⚠')\n",
    "            return OpenAIEmbeddings(model=modelname, api_key=st.session_state['api_key'])\n",
    "        elif model_type == 'ollama':\n",
    "            return OllamaEmbeddings(model=modelname)\n",
    "        elif model_type == 'sent':\n",
    "            print(model_type)\n",
    "            return HuggingFaceEmbeddings(model_name=modelname)\n",
    "        else:\n",
    "            return KeyError(f\"Model Type {model_type} not found\")\n",
    "    except KeyError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = get_embedding_model('all-MiniLM-L6-v2', model_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juggernautjha/.conda/envs/zener/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      ".gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 6.97MB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 533kB/s]\n",
      "README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 33.1MB/s]\n",
      "config.json: 100%|██████████| 612/612 [00:00<00:00, 2.40MB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 403kB/s]\n",
      "data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 1.58MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:07<00:00, 13.0MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 281kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 833kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 888kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 1.94MB/s]\n",
      "train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 40.8MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 778kB/s]\n",
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 1.83MB/s]\n"
     ]
    }
   ],
   "source": [
    "z = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zener",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
